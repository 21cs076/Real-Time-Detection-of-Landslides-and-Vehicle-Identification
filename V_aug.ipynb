{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21cs076/Real-Time-Detection-of-Landslides-and-Vehicle-Identification/blob/main/V_aug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1Osx24WyvK8"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define augmentation pipeline\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.1),\n",
        "    A.Rotate(limit=90, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.2))\n",
        "\n",
        "def read_label(label_path):\n",
        "    labels = []\n",
        "    with open(label_path, 'r') as file:\n",
        "        for line in file.readlines():\n",
        "            if line.strip():\n",
        "                class_id, x, y, w, h = map(float, line.strip().split())\n",
        "                labels.append([class_id, x, y, w, h])\n",
        "    return np.array(labels)\n",
        "\n",
        "def save_label(label_path, labels):\n",
        "    with open(label_path, 'w') as file:\n",
        "        for label in labels:\n",
        "            file.write(' '.join(map(str, label)) + '\\n')\n",
        "\n",
        "def augment_and_save(image_path, label_path, save_image_path, save_label_path, transform, num_augmented):\n",
        "    image = cv2.imread(image_path)\n",
        "    labels = read_label(label_path)\n",
        "\n",
        "    if labels.size == 0:  # Skip augmentation if no labels are found\n",
        "        return\n",
        "\n",
        "    class_labels = labels[:, 0]\n",
        "    bboxes = labels[:, 1:]\n",
        "\n",
        "    for i in range(num_augmented):\n",
        "        transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "        augmented_image = transformed['image']\n",
        "        augmented_bboxes = transformed['bboxes']\n",
        "\n",
        "        if len(augmented_bboxes) == 0:  # Skip if no bounding boxes remain after augmentation\n",
        "            continue\n",
        "\n",
        "        augmented_labels = np.hstack((np.array(transformed['class_labels'])[:, np.newaxis], augmented_bboxes))\n",
        "\n",
        "        augmented_image_path = os.path.join(save_image_path, f\"aug_{i}_{os.path.basename(image_path)}\")\n",
        "        augmented_label_path = os.path.join(save_label_path, f\"aug_{i}_{os.path.basename(label_path)}\")\n",
        "\n",
        "        cv2.imwrite(augmented_image_path, augmented_image)\n",
        "        save_label(augmented_label_path, augmented_labels)\n",
        "\n",
        "# Paths to your dataset images and labels\n",
        "dataset_image_path = \"/content/drive/MyDrive/Vehicle_Dataset/images\"\n",
        "dataset_label_path = \"/content/drive/MyDrive/Vehicle_Dataset/labels\"\n",
        "augmented_image_path = \"/content/drive/MyDrive/Vehicle_Dataset/aug/images\"\n",
        "augmented_label_path = \"/content/drive/MyDrive/Vehicle_Dataset/aug/labels\"\n",
        "\n",
        "os.makedirs(augmented_image_path, exist_ok=True)\n",
        "os.makedirs(augmented_label_path, exist_ok=True)\n",
        "\n",
        "# Augment each image and its corresponding label in the dataset\n",
        "for image_name in os.listdir(dataset_image_path):\n",
        "    image_path = os.path.join(dataset_image_path, image_name)\n",
        "    label_path = os.path.join(dataset_label_path, image_name.replace('.jpg', '.txt'))\n",
        "    augment_and_save(image_path, label_path, augmented_image_path, augmented_label_path, transform, num_augmented=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByIYpVnjywEa"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Ensure the augmented directories exist\n",
        "os.makedirs(augmented_image_path, exist_ok=True)\n",
        "os.makedirs(augmented_label_path, exist_ok=True)\n",
        "\n",
        "# Copy original images to the augmented images directory\n",
        "for image_name in os.listdir(dataset_image_path):\n",
        "    src_image_path = os.path.join(dataset_image_path, image_name)\n",
        "    dst_image_path = os.path.join(augmented_image_path, image_name)\n",
        "    shutil.copy(src_image_path, dst_image_path)\n",
        "\n",
        "# Copy original labels to the augmented labels directory\n",
        "for label_name in os.listdir(dataset_label_path):\n",
        "    src_label_path = os.path.join(dataset_label_path, label_name)\n",
        "    dst_label_path = os.path.join(augmented_label_path, label_name)\n",
        "    shutil.copy(src_label_path, dst_label_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7AedEuo39pT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def main():\n",
        "    # Define source paths\n",
        "    dataset_image_path = \"/content/drive/MyDrive/Vehicle_Dataset/nor/images\"\n",
        "    dataset_label_path = \"/content/drive/MyDrive/Vehicle_Dataset/nor/labels\"\n",
        "\n",
        "    # Define destination paths for images and labels\n",
        "    train_image_path = \"/content/drive/MyDrive/Vehicle_Dataset/train/images/\"\n",
        "    test_image_path = \"/content/drive/MyDrive/Vehicle_Dataset/test/images/\"\n",
        "    val_image_path = \"/content/drive/MyDrive/Vehicle_Dataset/valid/images/\"\n",
        "\n",
        "    train_label_path = \"/content/drive/MyDrive/Vehicle_Dataset/train/labels/\"\n",
        "    test_label_path = \"/content/drive/MyDrive/Vehicle_Dataset/test/labels/\"\n",
        "    val_label_path = \"/content/drive/MyDrive/Vehicle_Dataset/valid/labels/\"\n",
        "\n",
        "    # Create destination directories for images and labels\n",
        "    os.makedirs(train_image_path, exist_ok=True)\n",
        "    os.makedirs(test_image_path, exist_ok=True)\n",
        "    os.makedirs(val_image_path, exist_ok=True)\n",
        "    os.makedirs(train_label_path, exist_ok=True)\n",
        "    os.makedirs(test_label_path, exist_ok=True)\n",
        "    os.makedirs(val_label_path, exist_ok=True)\n",
        "\n",
        "    # Get all image files (supports .jpg, .jpeg, .png)\n",
        "    images = [f for f in os.listdir(dataset_image_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    total_images = len(images)\n",
        "    train_split = int(0.8 * total_images)\n",
        "    test_split = int(0.9 * total_images)  # 80% train, next 10% test, remaining 10% validation\n",
        "\n",
        "    train_images = images[:train_split]\n",
        "    test_images = images[train_split:test_split]\n",
        "    val_images = images[test_split:]\n",
        "\n",
        "    # Move image and corresponding label files for training dataset\n",
        "    for image_file in train_images:\n",
        "        # Move image\n",
        "        src_image = os.path.join(dataset_image_path, image_file)\n",
        "        dst_image = os.path.join(train_image_path, image_file)\n",
        "        shutil.move(src_image, dst_image)\n",
        "\n",
        "        # Build corresponding label file name (assumed to be .txt)\n",
        "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
        "        src_label = os.path.join(dataset_label_path, label_file)\n",
        "        dst_label = os.path.join(train_label_path, label_file)\n",
        "        if os.path.exists(src_label):\n",
        "            shutil.move(src_label, dst_label)\n",
        "        else:\n",
        "            print(f\"Warning: No label file found for training image: {image_file}\")\n",
        "\n",
        "    # Move image and corresponding label files for testing dataset\n",
        "    for image_file in test_images:\n",
        "        src_image = os.path.join(dataset_image_path, image_file)\n",
        "        dst_image = os.path.join(test_image_path, image_file)\n",
        "        shutil.move(src_image, dst_image)\n",
        "\n",
        "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
        "        src_label = os.path.join(dataset_label_path, label_file)\n",
        "        dst_label = os.path.join(test_label_path, label_file)\n",
        "        if os.path.exists(src_label):\n",
        "            shutil.move(src_label, dst_label)\n",
        "        else:\n",
        "            print(f\"Warning: No label file found for testing image: {image_file}\")\n",
        "\n",
        "    # Move image and corresponding label files for validation dataset\n",
        "    for image_file in val_images:\n",
        "        src_image = os.path.join(dataset_image_path, image_file)\n",
        "        dst_image = os.path.join(val_image_path, image_file)\n",
        "        shutil.move(src_image, dst_image)\n",
        "\n",
        "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
        "        src_label = os.path.join(dataset_label_path, label_file)\n",
        "        dst_label = os.path.join(val_label_path, label_file)\n",
        "        if os.path.exists(src_label):\n",
        "            shutil.move(src_label, dst_label)\n",
        "        else:\n",
        "            print(f\"Warning: No label file found for validation image: {image_file}\")\n",
        "\n",
        "    print(f\"Moved {len(train_images)} images and their corresponding labels to training set.\")\n",
        "    print(f\"Moved {len(test_images)} images and their corresponding labels to testing set.\")\n",
        "    print(f\"Moved {len(val_images)} images and their corresponding labels to validation set.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t33Iom-f4LF7"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "data = {\n",
        "    'train': \"/content/drive/MyDrive/Vehicle_Dataset/train/images\",\n",
        "    'val': \"/content/drive/MyDrive/Vehicle_Dataset/valid/images\",\n",
        "    'test': \"/content/drive/MyDrive/Vehicle_Dataset/test/images\",\n",
        "    'nc': 5,\n",
        "    'names': ['camping car', 'car', 'pickup', 'truck', 'van']\n",
        "}\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Vehicle_Dataset/data.yaml\", 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}