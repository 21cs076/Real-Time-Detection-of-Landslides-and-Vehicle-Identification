{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HuGtnr1trdlr"},"outputs":[],"source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"4MptKsSsONT0fnQsIDc2\")\n","project = rf.workspace(\"deslizamentos\").project(\"landslide-detection-augmentation\")\n","version = project.version(12)\n","dataset = version.download(\"yolov11\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76503,"status":"ok","timestamp":1739591411591,"user":{"displayName":"Athul P Benny","userId":"03291580115033758179"},"user_tz":-330},"id":"sUq3GDqDl2Sv","outputId":"1ea509fc-9c8c-4c3f-ca82-f42e2092e60b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":27862,"status":"ok","timestamp":1739589230918,"user":{"displayName":"Athul P Benny","userId":"03291580115033758179"},"user_tz":-330},"id":"y4gnuI0s1H4-","outputId":"f0129150-f402-42df-9c90-642e80ea77d4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Landslide_Dataset'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import shutil\n","\n","# Source folder (in Colab)\n","source_folder = \"/content/Landslide-Detection-Augmentation-12\"\n","\n","# Destination folder (in Google Drive)\n","destination_folder = \"/content/drive/MyDrive/Landslide_Dataset\"\n","\n","# Move the folder\n","shutil.move(source_folder, destination_folder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1Osx24WyvK8"},"outputs":[],"source":["import albumentations as A\n","import cv2\n","import os\n","import numpy as np\n","\n","# Define augmentation pipeline\n","transform = A.Compose([\n","    A.HorizontalFlip(p=0.4),\n","    A.VerticalFlip(p=0.2),\n","    A.Rotate(limit=15, p=0.5),\n","    A.RandomBrightnessContrast(p=0.2),\n","], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.2))\n","\n","def read_label(label_path):\n","    labels = []\n","    with open(label_path, 'r') as file:\n","        for line in file.readlines():\n","            if line.strip():\n","                class_id, x, y, w, h = map(float, line.strip().split())\n","                labels.append([class_id, x, y, w, h])\n","    return np.array(labels)\n","\n","def save_label(label_path, labels):\n","    with open(label_path, 'w') as file:\n","        for label in labels:\n","            file.write(' '.join(map(str, label)) + '\\n')\n","\n","def augment_and_save(image_path, label_path, save_image_path, save_label_path, transform, num_augmented):\n","    image = cv2.imread(image_path)\n","    labels = read_label(label_path)\n","\n","    if labels.size == 0:  # Skip augmentation if no labels are found\n","        return\n","\n","    class_labels = labels[:, 0]\n","    bboxes = labels[:, 1:]\n","\n","    for i in range(num_augmented):\n","        transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n","        augmented_image = transformed['image']\n","        augmented_bboxes = transformed['bboxes']\n","\n","        if len(augmented_bboxes) == 0:  # Skip if no bounding boxes remain after augmentation\n","            continue\n","\n","        augmented_labels = np.hstack((np.array(transformed['class_labels'])[:, np.newaxis], augmented_bboxes))\n","\n","        augmented_image_path = os.path.join(save_image_path, f\"aug_{i}_{os.path.basename(image_path)}\")\n","        augmented_label_path = os.path.join(save_label_path, f\"aug_{i}_{os.path.basename(label_path)}\")\n","\n","        cv2.imwrite(augmented_image_path, augmented_image)\n","        save_label(augmented_label_path, augmented_labels)\n","\n","# Paths to your dataset images and labels\n","dataset_image_path = \"/content/drive/MyDrive/Landslide_Dataset/images\"\n","dataset_label_path = \"/content/drive/MyDrive/Landslide_Dataset/labels\"\n","augmented_image_path = \"/content/drive/MyDrive/Landslide_Dataset/augt/images\"\n","augmented_label_path = \"/content/drive/MyDrive/Landslide_Dataset/augt/labels\"\n","\n","os.makedirs(augmented_image_path, exist_ok=True)\n","os.makedirs(augmented_label_path, exist_ok=True)\n","\n","# Augment each image and its corresponding label in the dataset\n","for image_name in os.listdir(dataset_image_path):\n","    image_path = os.path.join(dataset_image_path, image_name)\n","    label_path = os.path.join(dataset_label_path, image_name.replace('.jpg', '.txt'))\n","    augment_and_save(image_path, label_path, augmented_image_path, augmented_label_path, transform, num_augmented=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByIYpVnjywEa"},"outputs":[],"source":["import shutil\n","import os\n","\n","# Ensure the augmented directories exist\n","os.makedirs(augmented_image_path, exist_ok=True)\n","os.makedirs(augmented_label_path, exist_ok=True)\n","\n","# Copy original images to the augmented images directory\n","for image_name in os.listdir(dataset_image_path):\n","    src_image_path = os.path.join(dataset_image_path, image_name)\n","    dst_image_path = os.path.join(augmented_image_path, image_name)\n","    shutil.copy(src_image_path, dst_image_path)\n","\n","# Copy original labels to the augmented labels directory\n","for label_name in os.listdir(dataset_label_path):\n","    src_label_path = os.path.join(dataset_label_path, label_name)\n","    dst_label_path = os.path.join(augmented_label_path, label_name)\n","    shutil.copy(src_label_path, dst_label_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EyyLsLPe0qd6"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import shutil\n","\n","def main():\n","    # Define folder paths\n","    image_folder = \"/content/drive/MyDrive/Landslide_Dataset/augt/images\"                 # Folder with original images\n","    label_folder = \"/content/drive/MyDrive/Landslide_Dataset/augt/labels\"                   # Folder with YOLO label files\n","    output_image_folder = \"/content/drive/MyDrive/Landslide_Dataset/nor/images\"     # Folder to save normalized images\n","    output_label_folder = \"/content/drive/MyDrive/Landslide_Dataset/nor/labels\"       # Folder to copy label files\n","\n","    os.makedirs(output_image_folder, exist_ok=True)\n","    os.makedirs(output_label_folder, exist_ok=True)\n","\n","    # Get list of image files (supports .jpg, .jpeg, .png)\n","    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","    for image_file in image_files:\n","        image_path = os.path.join(image_folder, image_file)\n","        image = cv2.imread(image_path)\n","        if image is None:\n","            print(f\"Error reading image: {image_path}\")\n","            continue\n","\n","        # Normalize image pixel values to [0,1]\n","        image = image.astype(np.float32) / 255.0\n","\n","        # Convert normalized image back to 0-255 for saving (for visualization)\n","        normalized_image = (image * 255).astype(np.uint8)\n","        out_image_path = os.path.join(output_image_folder, image_file)\n","        cv2.imwrite(out_image_path, normalized_image)\n","\n","        # Copy the corresponding label file if it exists (labels are in YOLO format and already normalized)\n","        label_file = os.path.splitext(image_file)[0] + \".txt\"\n","        label_path = os.path.join(label_folder, label_file)\n","        if os.path.exists(label_path):\n","            out_label_path = os.path.join(output_label_folder, label_file)\n","            shutil.copy(label_path, out_label_path)\n","            print(f\"Processed image and copied label: {image_file}\")\n","        else:\n","            print(f\"No label file for image: {image_file}\")\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7AedEuo39pT"},"outputs":[],"source":["import os\n","import shutil\n","import random\n","\n","def main():\n","    # Define source paths\n","    dataset_image_path = \"/content/drive/MyDrive/Landslide_Dataset/normalized/images\"\n","    dataset_label_path = \"/content/drive/MyDrive/Landslide_Dataset/normalized/labels\"\n","\n","    # Define destination paths for images and labels\n","    train_image_path = \"/content/drive/MyDrive/Landslide_Dataset/train/images/\"\n","    test_image_path = \"/content/drive/MyDrive/Landslide_Dataset/test/images/\"\n","    val_image_path = \"/content/drive/MyDrive/Landslide_Dataset/valid/images/\"\n","\n","    train_label_path = \"/content/drive/MyDrive/Landslide_Dataset/train/labels/\"\n","    test_label_path = \"/content/drive/MyDrive/Landslide_Dataset/test/labels/\"\n","    val_label_path = \"/content/drive/MyDrive/Landslide_Dataset/valid/labels/\"\n","\n","    # Create destination directories for images and labels\n","    os.makedirs(train_image_path, exist_ok=True)\n","    os.makedirs(test_image_path, exist_ok=True)\n","    os.makedirs(val_image_path, exist_ok=True)\n","    os.makedirs(train_label_path, exist_ok=True)\n","    os.makedirs(test_label_path, exist_ok=True)\n","    os.makedirs(val_label_path, exist_ok=True)\n","\n","    # Get all image files (supports .jpg, .jpeg, .png)\n","    images = [f for f in os.listdir(dataset_image_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","    random.shuffle(images)\n","\n","    total_images = len(images)\n","    train_split = int(0.8 * total_images)\n","    test_split = int(0.9 * total_images)  # 80% train, next 10% test, remaining 10% validation\n","\n","    train_images = images[:train_split]\n","    test_images = images[train_split:test_split]\n","    val_images = images[test_split:]\n","\n","    # Move image and corresponding label files for training dataset\n","    for image_file in train_images:\n","        # Move image\n","        src_image = os.path.join(dataset_image_path, image_file)\n","        dst_image = os.path.join(train_image_path, image_file)\n","        shutil.move(src_image, dst_image)\n","\n","        # Build corresponding label file name (assumed to be .txt)\n","        label_file = os.path.splitext(image_file)[0] + \".txt\"\n","        src_label = os.path.join(dataset_label_path, label_file)\n","        dst_label = os.path.join(train_label_path, label_file)\n","        if os.path.exists(src_label):\n","            shutil.move(src_label, dst_label)\n","        else:\n","            print(f\"Warning: No label file found for training image: {image_file}\")\n","\n","    # Move image and corresponding label files for testing dataset\n","    for image_file in test_images:\n","        src_image = os.path.join(dataset_image_path, image_file)\n","        dst_image = os.path.join(test_image_path, image_file)\n","        shutil.move(src_image, dst_image)\n","\n","        label_file = os.path.splitext(image_file)[0] + \".txt\"\n","        src_label = os.path.join(dataset_label_path, label_file)\n","        dst_label = os.path.join(test_label_path, label_file)\n","        if os.path.exists(src_label):\n","            shutil.move(src_label, dst_label)\n","        else:\n","            print(f\"Warning: No label file found for testing image: {image_file}\")\n","\n","    # Move image and corresponding label files for validation dataset\n","    for image_file in val_images:\n","        src_image = os.path.join(dataset_image_path, image_file)\n","        dst_image = os.path.join(val_image_path, image_file)\n","        shutil.move(src_image, dst_image)\n","\n","        label_file = os.path.splitext(image_file)[0] + \".txt\"\n","        src_label = os.path.join(dataset_label_path, label_file)\n","        dst_label = os.path.join(val_label_path, label_file)\n","        if os.path.exists(src_label):\n","            shutil.move(src_label, dst_label)\n","        else:\n","            print(f\"Warning: No label file found for validation image: {image_file}\")\n","\n","    print(f\"Moved {len(train_images)} images and their corresponding labels to training set.\")\n","    print(f\"Moved {len(test_images)} images and their corresponding labels to testing set.\")\n","    print(f\"Moved {len(val_images)} images and their corresponding labels to validation set.\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t33Iom-f4LF7"},"outputs":[],"source":["import yaml\n","data = {\n","    'train': \"/content/drive/MyDrive/Landslide_Dataset/train/images\",\n","    'val': \"/content/drive/MyDrive/Landslide_Dataset/valid/images\",\n","    'test': \"/content/drive/MyDrive/Landslide_Dataset/test/images\",\n","    'nc': 2,\n","    'names': ['Fissure', 'Landslide']\n","}\n","with open(\"/content/drive/MyDrive/Landslide_Dataset/data.yaml\", 'w') as file:\n","    yaml.dump(data, file, default_flow_style=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nYIUhUMW04TS"},"outputs":[],"source":["import os\n","\n","def count_files(directory, extensions):\n","    \"\"\"\n","    Count the number of files in `directory` that have one of the specified `extensions`.\n","    \"\"\"\n","    return len([f for f in os.listdir(directory)\n","                if os.path.splitext(f)[1].lower() in extensions])\n","\n","def main():\n","    # Specify the directories for images and labels\n","    image_folder = \"/content/drive/MyDrive/Landslide_Dataset/normalized/images\"  # Change as required\n","    label_folder = \"/content/drive/MyDrive/Landslide_Dataset/normalized/labels/\"    # Change as required\n","\n","    # Define common file extensions for images and labels\n","    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'}\n","    label_extensions = {'.txt'}  # Assuming labels are stored as .txt files\n","\n","    # Count image and label files\n","    num_images = count_files(image_folder, image_extensions)\n","    num_labels = count_files(label_folder, label_extensions)\n","\n","    print(\"Number of images:\", num_images)\n","    print(\"Number of label files:\", num_labels)\n","\n","    # Optionally, if you want to report if any image doesn't have a corresponding label file,\n","    # you can do so by checking matching file names (without extensions).\n","    image_names = {os.path.splitext(f)[0] for f in os.listdir(image_folder)\n","                   if os.path.splitext(f)[1].lower() in image_extensions}\n","    label_names = {os.path.splitext(f)[0] for f in os.listdir(label_folder)\n","                   if os.path.splitext(f)[1].lower() in label_extensions}\n","\n","    missing_labels = image_names - label_names\n","    missing_images = label_names - image_names\n","\n","    if missing_labels:\n","        print(\"\\nImages missing corresponding label files:\")\n","        for name in missing_labels:\n","            print(\" -\", name)\n","    else:\n","        print(\"\\nAll images have corresponding label files.\")\n","\n","    if missing_images:\n","        print(\"\\nLabel files without corresponding images:\")\n","        for name in missing_images:\n","            print(\" -\", name)\n","    else:\n","        print(\"\\nAll label files have corresponding images.\")\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}